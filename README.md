[![Typing SVG](https://readme-typing-svg.demolab.com/?width=500&lines=Hello+there+,+Welcome+to+my+Portfolio)](https://git.io/typing-svg)


I am an individual passionate about data and enjoy using it to solve problems. Today, I present to you an intriguing project centered around gathering social media data and applying text modeling and sentiment analysis techniques to it. By delving into this project, we encountered a challenge in choosing between two popular and relevant topics.
## The topic for the project is the one and only ChatGPT


# Sentiment-Analysis
**Business Problem**: As a consequence of chat-GPT sometimes generating imprecise or nonsensical replies, our users are encountering a less-than-ideal experience, leading to reduced satisfaction and interaction with our platform. It is imperative that we enhance the accuracy and dependability of our chat-GPT, so that it can unfailingly generate superior responses to user inquiries, thereby enriching the user experience and fostering greater engagement.

**Data Source**: Reddit is a social news and conversation website where registered members can submit text posts and direct links.

**Data Collection**: We collected 13K subreddits for over a month. The API (Application Programming Interface) methodologies were employed to collect the data. APIs facilitate communication between applications and different software components, allowing them to extract data from various sources. This approach guarantees that the data collected is precise and comprehensive.

**Challenges Faced with Data**: 

* Social media data derived from platforms like Twitter and Reddit may contain noise and clutter due to the use of abbreviations, slang, and misspellings, making it challenging to precisely identify pertinent data.
* Another obstacle to gathering data from social media platforms is the inconsistency in the quality of the content. Certain posts may be of low quality, containing irrelevant information or being spam.
* API data collection can be constrained by limitations such as rate limits or restricted access to particular data types, which can impact the quantity and quality of the data gathered.
* Preprocessing and cleansing the data can also be a time-intensive endeavor, especially when dealing with vast amounts of data.





